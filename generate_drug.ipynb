{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq = pd.read_csv('data/UnlabeledSmilesDataset.csv',header=None) # got this dataset from https://www.kaggle.com/antifact/molecular-translation-smiles-csv/code\r\n",
    "# as far as I can tell it is just a bunch of smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1741212"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq = df_seq[0]\r\n",
    "len(df_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0              CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\n1         C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1\n2    N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...\n3    CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...\n4    N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...\nName: 0, dtype: object"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_codes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "import argparse\n",
    "import warnings\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def get_vocabulary(fobj, is_dict=False):\n",
    "    \"\"\"Read text and return dictionary that encodes vocabulary\n",
    "    vocab = Counter()\n",
    "    for i, line in enumerate(fobj):\n",
    "        if is_dict:\n",
    "            try:\n",
    "                word, count = line.strip('\\r\\n ').split(' ')\n",
    "            except:\n",
    "                print('Failed reading vocabulary file at line {0}: {1}'.format(i, line))\n",
    "                sys.exit(1)\n",
    "            vocab[word] += int(count)\n",
    "        else:\n",
    "            for word in line.strip('\\r\\n ').split(' '):\n",
    "                if word:\n",
    "                    vocab[word] += 1\n",
    "        \"\"\"\n",
    "    \n",
    "    vocab = Counter()\n",
    "    for word in fobj:\n",
    "        vocab[word] += 1\n",
    "    return vocab\n",
    "\n",
    "def update_pair_statistics(pair, changed, stats, indices):\n",
    "    \"\"\"Minimally update the indices and frequency of symbol pairs\n",
    "    if we merge a pair of symbols, only pairs that overlap with occurrences\n",
    "    of this pair are affected, and need to be updated.\n",
    "    \"\"\"\n",
    "    stats[pair] = 0\n",
    "    indices[pair] = defaultdict(int)\n",
    "    first, second = pair\n",
    "    new_pair = first+second\n",
    "    for j, word, old_word, freq in changed:\n",
    "\n",
    "        # find all instances of pair, and update frequency/indices around it\n",
    "        i = 0\n",
    "        while True:\n",
    "            # find first symbol\n",
    "            try:\n",
    "                i = old_word.index(first, i)\n",
    "            except ValueError:\n",
    "                break\n",
    "            # if first symbol is followed by second symbol, we've found an occurrence of pair (old_word[i:i+2])\n",
    "            if i < len(old_word)-1 and old_word[i+1] == second:\n",
    "                # assuming a symbol sequence \"A B C\", if \"B C\" is merged, reduce the frequency of \"A B\"\n",
    "                if i:\n",
    "                    prev = old_word[i-1:i+1]\n",
    "                    stats[prev] -= freq\n",
    "                    indices[prev][j] -= 1\n",
    "                if i < len(old_word)-2:\n",
    "                    # assuming a symbol sequence \"A B C B\", if \"B C\" is merged, reduce the frequency of \"C B\".\n",
    "                    # however, skip this if the sequence is A B C B C, because the frequency of \"C B\" will be reduced by the previous code block\n",
    "                    if old_word[i+2] != first or i >= len(old_word)-3 or old_word[i+3] != second:\n",
    "                        nex = old_word[i+1:i+3]\n",
    "                        stats[nex] -= freq\n",
    "                        indices[nex][j] -= 1\n",
    "                i += 2\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            try:\n",
    "                # find new pair\n",
    "                i = word.index(new_pair, i)\n",
    "            except ValueError:\n",
    "                break\n",
    "            # assuming a symbol sequence \"A BC D\", if \"B C\" is merged, increase the frequency of \"A BC\"\n",
    "            if i:\n",
    "                prev = word[i-1:i+1]\n",
    "                stats[prev] += freq\n",
    "                indices[prev][j] += 1\n",
    "            # assuming a symbol sequence \"A BC B\", if \"B C\" is merged, increase the frequency of \"BC B\"\n",
    "            # however, if the sequence is A BC BC, skip this step because the count of \"BC BC\" will be incremented by the previous code block\n",
    "            if i < len(word)-1 and word[i+1] != new_pair:\n",
    "                nex = word[i:i+2]\n",
    "                stats[nex] += freq\n",
    "                indices[nex][j] += 1\n",
    "            i += 1\n",
    "\n",
    "\n",
    "def get_pair_statistics(vocab):\n",
    "    \"\"\"Count frequency of all symbol pairs, and create index\"\"\"\n",
    "\n",
    "    # data structure of pair frequencies\n",
    "    stats = defaultdict(int)\n",
    "\n",
    "    #index from pairs to words\n",
    "    indices = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for i, (word, freq) in enumerate(vocab):\n",
    "        prev_char = word[0]\n",
    "        for char in word[1:]:\n",
    "            stats[prev_char, char] += freq\n",
    "            indices[prev_char, char][i] += 1\n",
    "            prev_char = char\n",
    "\n",
    "    return stats, indices\n",
    "\n",
    "\n",
    "def replace_pair(pair, vocab, indices):\n",
    "    \"\"\"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\"\"\"\n",
    "    first, second = pair\n",
    "    pair_str = ''.join(pair)\n",
    "    pair_str = pair_str.replace('\\\\','\\\\\\\\')\n",
    "    changes = []\n",
    "    pattern = re.compile(r'(?<!\\S)' + re.escape(first + ' ' + second) + r'(?!\\S)')\n",
    "    if sys.version_info < (3, 0):\n",
    "        iterator = indices[pair].iteritems()\n",
    "    else:\n",
    "        iterator = indices[pair].items()\n",
    "    for j, freq in iterator:\n",
    "        if freq < 1:\n",
    "            continue\n",
    "        word, freq = vocab[j]\n",
    "        new_word = ' '.join(word)\n",
    "        new_word = pattern.sub(pair_str, new_word)\n",
    "        new_word = tuple(new_word.split(' '))\n",
    "\n",
    "        vocab[j] = (new_word, freq)\n",
    "        changes.append((j, new_word, word, freq))\n",
    "\n",
    "    return changes\n",
    "\n",
    "def prune_stats(stats, big_stats, threshold):\n",
    "    \"\"\"Prune statistics dict for efficiency of max()\n",
    "    The frequency of a symbol pair never increases, so pruning is generally safe\n",
    "    (until we the most frequent pair is less frequent than a pair we previously pruned)\n",
    "    big_stats keeps full statistics for when we need to access pruned items\n",
    "    \"\"\"\n",
    "    for item,freq in list(stats.items()):\n",
    "        if freq < threshold:\n",
    "            del stats[item]\n",
    "            if freq < 0:\n",
    "                big_stats[item] += freq\n",
    "            else:\n",
    "                big_stats[item] = freq\n",
    "\n",
    "\n",
    "def learn_bpe(infile, outfile, num_symbols, min_frequency=2, verbose=False, is_dict=False, total_symbols=False):\n",
    "    \"\"\"Learn num_symbols BPE operations from vocabulary, and write to outfile.\n",
    "    \"\"\"\n",
    "\n",
    "    # version 0.2 changes the handling of the end-of-word token ('</w>');\n",
    "    # version numbering allows bckward compatibility\n",
    "    outfile.write('#version: 0.2\\n')\n",
    "\n",
    "    vocab = get_vocabulary(infile, is_dict)\n",
    "    vocab = dict([(tuple(x[:-1])+(x[-1]+'</w>',) ,y) for (x,y) in vocab.items()])\n",
    "    sorted_vocab = sorted(vocab.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    stats, indices = get_pair_statistics(sorted_vocab)\n",
    "    big_stats = copy.deepcopy(stats)\n",
    "\n",
    "    if total_symbols:\n",
    "        uniq_char_internal = set()\n",
    "        uniq_char_final = set()\n",
    "        for word in vocab:\n",
    "            for char in word[:-1]:\n",
    "                uniq_char_internal.add(char)\n",
    "            uniq_char_final.add(word[-1])\n",
    "        sys.stderr.write('Number of word-internal characters: {0}\\n'.format(len(uniq_char_internal)))\n",
    "        sys.stderr.write('Number of word-final characters: {0}\\n'.format(len(uniq_char_final)))\n",
    "        sys.stderr.write('Reducing number of merge operations by {0}\\n'.format(len(uniq_char_internal) + len(uniq_char_final)))\n",
    "        num_symbols -= len(uniq_char_internal) + len(uniq_char_final)\n",
    "        for i in uniq_char_internal:\n",
    "            vocab_index2units2freq[i] = 0\n",
    "\n",
    "    # threshold is inspired by Zipfian assumption, but should only affect speed\n",
    "    threshold = max(stats.values()) / 10\n",
    "    for i in range(num_symbols):\n",
    "        if stats:\n",
    "            most_frequent = max(stats, key=lambda x: (stats[x], x))\n",
    "\n",
    "        # we probably missed the best pair because of pruning; go back to full statistics\n",
    "        if not stats or (i and stats[most_frequent] < threshold):\n",
    "            prune_stats(stats, big_stats, threshold)\n",
    "            stats = copy.deepcopy(big_stats)\n",
    "            most_frequent = max(stats, key=lambda x: (stats[x], x))\n",
    "            # threshold is inspired by Zipfian assumption, but should only affect speed\n",
    "            threshold = stats[most_frequent] * i/(i+10000.0)\n",
    "            prune_stats(stats, big_stats, threshold)\n",
    "\n",
    "        if stats[most_frequent] < min_frequency:\n",
    "            sys.stderr.write('no pair has frequency >= {0}. Stopping\\n'.format(min_frequency))\n",
    "            break\n",
    "        \n",
    "        #essential\n",
    "        s1 = most_frequent[0].replace('</w>','')\n",
    "        s2 = most_frequent[1].replace('</w>','')\n",
    "        \n",
    "        vocab_index2units2freq[s1+s2] = stats[most_frequent]\n",
    "        \n",
    "        if verbose:\n",
    "            sys.stderr.write('pair {0}: {1} {2} -> {1}{2} (frequency {3})\\n'.format(i, most_frequent[0], most_frequent[1], stats[most_frequent]))\n",
    "        outfile.write('{0} {1}\\n'.format(*most_frequent))\n",
    "        freq_codes.append(most_frequent)\n",
    "        changes = replace_pair(most_frequent, sorted_vocab, indices)\n",
    "        update_pair_statistics(most_frequent, changes, stats, indices)\n",
    "        stats[most_frequent] = 0\n",
    "        if not i % 100:\n",
    "            prune_stats(stats, big_stats, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7036a927e977>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvocab_index2units2freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./drug_codes_chembl_freq_1500.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlearn_bpe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_frequency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_symbols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "vocab_index2units2freq = {}\n",
    "seq = (df_seq[0].values)\n",
    "output = open('./drug_codes_chembl_freq_1500.txt', 'w+')\n",
    "learn_bpe(seq, output, 30000, min_frequency=1500, verbose=True, is_dict=False, total_symbols=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subword_nmt.apply_bpe import BPE\n",
    "import codecs \n",
    "\n",
    "bpe_codes_fin = codecs.open('./ESPF/drug_codes_chembl_freq_1500.txt')\n",
    "bpe = BPE(bpe_codes_fin, merges=-1, separator='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC(C)C (=C )CC (O)C (C) (O) [C@H]1CC [C@H]2C 3=C [C@H](OC(=O)C) [C@H]4 [C@@H](OC(=O)C) [C@@H](O)CC [C@]4(C)[C@H]3CC [C@]12C'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.process_line(df_seq[0].values[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC(C)C(=C)CC(O)C(C)(O)[C@H]1CC[C@H]2C3=C[C@H](OC(=O)C)[C@H]4[C@@H](OC(=O)C)[C@@H](O)CC[C@]4(C)[C@H]3CC[C@]12C'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq[0].values[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = list(vocab_index2units2freq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2idx = dict(zip(vocab_index2units2freq.keys(), range(0, len(idx2word))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_length_count = defaultdict(int)\n",
    "for i in range(len(list(vocab_index2units2freq.keys()))):\n",
    "    word_length_count[len(list(vocab_index2units2freq.keys())[i])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 31 artists>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(list(word_length_count.keys()), list(word_length_count.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {1: 59,\n",
       "             2: 124,\n",
       "             3: 241,\n",
       "             4: 310,\n",
       "             5: 303,\n",
       "             6: 292,\n",
       "             7: 259,\n",
       "             8: 253,\n",
       "             9: 203,\n",
       "             10: 131,\n",
       "             11: 108,\n",
       "             12: 68,\n",
       "             13: 55,\n",
       "             14: 37,\n",
       "             15: 28,\n",
       "             16: 25,\n",
       "             17: 24,\n",
       "             18: 16,\n",
       "             19: 7,\n",
       "             20: 9,\n",
       "             21: 6,\n",
       "             22: 7,\n",
       "             23: 5,\n",
       "             24: 6,\n",
       "             25: 3,\n",
       "             26: 1,\n",
       "             27: 2,\n",
       "             28: 1,\n",
       "             30: 1,\n",
       "             36: 1,\n",
       "             48: 1})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_length_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_csv = pd.DataFrame(list(vocab_index2units2freq.items()),\n",
    "                      columns=['index','frequency'])\n",
    "sub_csv.reset_index(level=0, inplace=True)\n",
    "sub_csv.to_csv('./subword_units_map_chembl_freq_1500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['V', 'b', 'G', ..., 'c(C)c3', '#N)cc1', 'c5cc6'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sub_csv['index'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('SpringBoardRoot': conda)",
   "name": "python388jvsc74a57bd034254dbed0a11299c26a60998b10651945ddc6175a352e28bb4ea7f4f8edb40d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}